# }
query_params2 <- list(
geometry = '{
"xmin": -10394540.56,
"ymin": 5603024.26,
"xmax": -10373503.03,
"ymax":  5629581.38,
"spatialReference": {"wkid":102100}
}',
geometryType2 = "esriGeometryEnvelope",
outFields = "*",
f = "geojson"
)
response2 <- GET(base_url2, query = query_params2)
geojson_data2 <- content(response2, as = "text", encoding = "UTF-8") %>% fromJSON()
temp_geojson2 <- tempfile(fileext = ".geojson")
writeBin(content(response2, as = "raw"), temp_geojson2)
# Read the GeoJSON data as a shape file object
geojson_sf_2 <- st_read(temp_geojson2)
# Downloading other important data from GitHub
air_pollution <- read.csv("../data/air_pollution_data_mn.csv") # Charles
# Downloading other important data from GitHub
air_pollution <- read.csv("../data/raw/air_pollution_data_mn.csv")
racial_covenants <- read.csv("../data/raw/Hennepin_County_Racial_Covenants_Table.csv")
tree_canopy <- read.csv("../data/raw/minneapolis-tree-canopy.csv")
svi <- read.csv("../data/clean/svi.csv")
holc <- st_read("../data/clean/redlining_msp.shp")
# Downloading other important data from GitHub
air_pollution <- read.csv("../data/raw/air_pollution_data_mn.csv")
racial_covenants <- read.csv("../data/raw/Hennepin_County_Racial_Covenants_Table.csv")
tree_canopy <- read.csv("../data/raw/minneapolis-tree-canopy.csv")
svi <- read.csv("../data/clean/svi.csv")
holc <- st_read("../data/clean/redlining_msp_shp/redlining_msp.shp")
# Downloading other important data from GitHub
air_pollution <- read.csv("../data/raw/air_pollution_data_mn.csv")
racial_covenants <- read.csv("../data/raw/Hennepin_County_Racial_Covenants_Table.csv")
tree_canopy <- read.csv("../data/raw/minneapolis-tree-canopy.csv")
svi <- read.csv("../data/clean/svi.csv")
holc <- st_read("../data/clean/redlining_msp_shp/redlining_msp.shp")
air_pollution <- air_pollution %>%
filter(COUNTY == "Hennepin")
racial_covenants <- racial_covenants %>%
filter(City == "MINNEAPOLIS")
svi <- svi %>%
filter(COUNTY == "Hennepin County")
View(svi)
# Downloading other important data from GitHub
air_pollution <- read.csv("../data/raw/air_pollution_data_mn.csv")
racial_covenants <- read.csv("../data/raw/Hennepin_County_Racial_Covenants_Table.csv")
tree_canopy <- read.csv("../data/raw/minneapolis-tree-canopy.csv")
svi <- read.csv("../data/clean/svi.csv")
holc <- st_read("../data/clean/redlining_msp_shp/redlining_msp.shp")
air_pollution <- air_pollution %>%
filter(COUNTY == "Hennepin")
racial_covenants <- racial_covenants %>%
filter(City == "MINNEAPOLIS")
holc <- holc %>%
filter(city == "Minneapolis")
# Downloading other important data from GitHub
air_pollution <- read.csv("../data/raw/air_pollution_data_mn.csv")
racial_covenants <- read.csv("../data/raw/Hennepin_County_Racial_Covenants_Table.csv")
tree_canopy <- read.csv("../data/raw/minneapolis-tree-canopy.csv")
svi <- read.csv("../data/clean/svi.csv")
holc <- st_read("../data/clean/redlining_msp_shp/redlining_msp.shp")
air_pollution <- air_pollution %>%
filter(COUNTY == "Hennepin")
racial_covenants <- racial_covenants %>%
filter(City == "MINNEAPOLIS")
# Downloading other important data from GitHub
svi <- read.csv("../data/clean/svi.csv")
holc <- st_read("../data/clean/redlining_msp_shp/redlining_msp.shp")
library(tigris)
library(tidycensus)
options(tigris_use_cache = TRUE)
mn_census_tract <- tracts(state = "MN", cb = FALSE, year = 2022) %>%
filter(COUNTYFP == "053") # collect hennepin county census tracts
minneapolis_boundary <- places(state = "MN", year = 2022, class = "sf") %>%
filter(NAME == "Minneapolis")
mn_lake <- area_water(state = "MN", count = 'Hennepin')
mpls_tracts <- st_intersection(mn_census_tract, minneapolis_boundary)
mpls_lakes <- st_intersection(mn_lake, minneapolis_boundary)
mpls_tracts <- st_transform(mpls_tracts, 4326) # make the same crs
mpls_lakes <- st_transform(mpls_lakes, 4326) # make the same crs
parks_in_tracts <- st_intersection(mpls_tracts, geojson_sf_2) # get overlapping area
parks_in_tracts_2 <- parks_in_tracts %>%
st_difference(st_union(mpls_lakes))
lakeless_tracts <- mpls_tracts %>%
st_difference(st_union(mpls_lakes))
# Goal: Create data frame with park area per tract
parks_in_tracts_3 <- parks_in_tracts_2 %>%
group_by(GEOID) %>% # Group by census tract
mutate(total_park_area = (sum(ACRES)*4046.86)) %>% # add total park acres per census tract and convert units
select(GEOID, total_park_area) %>% # select important cols
distinct(GEOID, .keep_all = TRUE) %>% # Get one number for each tract
st_drop_geometry() # Drop geometry for further data merge
# It is okay to drop geometry here because we are only going for the number area, not the shape of the park areas in the census tracts.
lakeless_tracts <- st_make_valid(lakeless_tracts)
# Goal: Add the total_park_area column to the mn_census_tract data so we can make a map with the total_park_area as the fill variable
mn_census_tract_2 <- lakeless_tracts %>%
left_join(parks_in_tracts_3, by = "GEOID") %>% # Match all ocurrences
mutate(total_park_area = replace_na(total_park_area, 0)) %>%
mutate(park_area_ratio = total_park_area / st_area(lakeless_tracts)) %>%
mutate(park_area_ratio = str_remove(park_area_ratio, "[1/m^2]")) %>%
mutate(park_area_ratio = as.numeric(park_area_ratio))
library(stringr)
# Goal: Create data frame with park area per tract
parks_in_tracts_3 <- parks_in_tracts_2 %>%
group_by(GEOID) %>% # Group by census tract
mutate(total_park_area = (sum(ACRES)*4046.86)) %>% # add total park acres per census tract and convert units
select(GEOID, total_park_area) %>% # select important cols
distinct(GEOID, .keep_all = TRUE) %>% # Get one number for each tract
st_drop_geometry() # Drop geometry for further data merge
# It is okay to drop geometry here because we are only going for the number area, not the shape of the park areas in the census tracts.
lakeless_tracts <- st_make_valid(lakeless_tracts)
# Goal: Add the total_park_area column to the mn_census_tract data so we can make a map with the total_park_area as the fill variable
mn_census_tract_2 <- lakeless_tracts %>%
left_join(parks_in_tracts_3, by = "GEOID") %>% # Match all ocurrences
mutate(total_park_area = replace_na(total_park_area, 0)) %>%
mutate(park_area_ratio = total_park_area / st_area(lakeless_tracts)) %>%
mutate(park_area_ratio = str_remove(park_area_ratio, "[1/m^2]")) %>%
mutate(park_area_ratio = as.numeric(park_area_ratio))
#| include: false
knitr::opts_chunk$set(error=TRUE)
#| message: false
#| code-fold: true
# load packages
library(tidyverse)
library(tidymodels)
library(factoextra)
# read data
music <- read_csv("https://bcheggeseth.github.io/253_spring_2024/data/billboard.csv")
# find artists with at least 50 songs
topperformers <- music %>%
count(performer) %>%
filter(n >= 50) %>%
pull(performer)
# data cleaning
topartists <- music %>%
filter(performer %in% topperformers) %>%
# for each artist, find the song(s) with the longest billboard reign
group_by(performer) %>%
slice_max(billboard_weeks) %>%
# to break ties, find the song(s) with the highest spotify popularity
group_by(performer) %>%
slice_max(spotify_popularity) %>%
ungroup() %>%
# remove some variables we don't want to deal with
select(-key, -mode, -time_signature, -song)
# check it out
print(topartists)
#| code-fold: true
topartists_clean <- topartists %>%
column_to_rownames('performer')
#| fig-width: 10
#| fig-height: 3
#| warning: false
# implement hierarchical clustering
# NOTE: make sure you use the "clean" data you created above
hier_model <- hclust(dist(scale(topartists_clean)), method = "complete")
# plot the dendrogram
# color the leaves and branches according to their cluster assignment
fviz_dend(hier_model, horiz = TRUE, k = 4, cex = 0.8)
# plot a heatmap
# order the rows according to the dendrogram
heatmap(scale(data.matrix(topartists_clean)), Colv = NA)
set.seed(253)
kmeans_model <- kmeans(scale(topartists_clean), centers = 4)
# Store it under a new name in case of mistakes!
topartists_clustered <- topartists_clean %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Print results
topartists_clustered
# Store it under a new name in case of mistakes!
topartists_clustered <- scale(topartists_clean) %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Store it under a new name in case of mistakes!
topartists_clustered <- topartists_clean %>%
mutate(cluster_number = kmeans_model$cluster) %>%
scale(cluster_number)
topartists_clustered <- topartists_clean %>%
mutate(cluster_number = kmeans_model$cluster)
# Store it under a new name in case of mistakes!
topartists_clustered <- scale(data.matrix(topartists_clean)) %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Store it under a new name in case of mistakes!
topartists_clustered <- scale(topartists_clean) %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Store it under a new name in case of mistakes!
topartists_clustered <- topartists_clean %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Print results
topartists_clustered
# Store it under a new name in case of mistakes!
topartists_clustered <- data.matrix(scalae(topartists_clean)) %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Store it under a new name in case of mistakes!
topartists_clustered <- data.matrix(scale(topartists_clean)) %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Store it under a new name in case of mistakes!
topartists_clustered <- topartists_clean %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
# Print results
topartists_clustered
lm_spec <- linear_reg() %>%
set_mode("regression") %>%
set_engine("lm")
pcr_recipe <- recipe(spotify_popularity ~ ., data = topartists) %>%
update_role(performer, new_role = "id") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_predictors()) %>%
step_pca(all_predictors(), num_comp = tune())
pcr_workflow <- workflow() %>%
add_recipe(pcr_recipe) %>%
add_model(lm_spec)
set.seed(253)
pcr_models <- pcr_workflow %>%
tune_grid(
grid = grid_regular(num_comp(range = c(1, 7)), levels = 7),
resamples = vfold_cv(topartists, v = 10),
metrics = metric_set(mae)
)
pcr_models %>%
autoplot()
View(topartists_clean)
# Store it under a new name in case of mistakes!
topartists_clustered <- topartists_clean %>%
scale() %>%
mutate(cluster_number = kmeans_model$cluster) %>%
group_by(cluster_number)
cluster_labels <- cutree(complete_model, k = 2)
# OPTIONAL: Set a more color blind friendly palette
palette("Okabe-Ito")
scale_colour_discrete <- function(...) scale_colour_manual(values = palette())
scale_fill_discrete   <- function(...) scale_fill_manual(values = palette())
knitr::opts_chunk$set(
collapse = TRUE,
warning = FALSE,
message = FALSE,
fig.height = 2.75,
fig.width = 4.25,
fig.env='figure',
fig.pos = 'h',
fig.align = 'center')
library(tidyverse)
library(dplyr)
library(factoextra)
music <- read_csv("https://bcheggeseth.github.io/253_spring_2024/data/billboard.csv")
# check it out
head(music)
# Check out artists with at least 25 songs
music %>%
count(performer) %>%
filter(n >= 25) %>%
select(performer)
# Pick just one of these artists to study
my_artist <- music %>%
filter(performer == "Ariana Grande") %>%
select(-performer) %>%
group_by(song) %>%       # The last rows deal w songs that appear more than once
slice_sample(n = 1) %>%
ungroup()
selected_songs <- my_artist %>%
column_to_rownames(var = "song")
# Heatmap
standardized_artist <- scale(data.matrix(selected_songs))
heatmap(scale(data.matrix(standardized_artist)), Colv = NA)
complete_model <- hclust(dist(standardized_artist), method = "complete")
fviz_dend(complete_model, horiz = TRUE, cex = 0.4, k = 2)
cluster_labels <- cutree(complete_model, k = 2)
clustered_songs <- selected_songs %>%
mutate(cluster = cluster_labels)
clustered_songs%>%
group_by(cluster) %>%
summarise_all(mean, na.rm = TRUE)
clustered_songs <- selected_songs %>%
mutate(cluster = scale(cluster_labels))
cluster_labels <- cutree(complete_model, k = 2)
clustered_songs <- selected_songs %>%
mutate(cluster = scale(cluster_labels))
clustered_songs%>%
group_by(cluster) %>%
summarise_all(mean, na.rm = TRUE)
cluster_labels <- cutree(complete_model, k = 2)
clustered_songs <- selected_songs %>%
mutate(cluster = cluster_labels)
clustered_songs%>%
group_by(cluster) %>%
summarise_all(mean, na.rm = TRUE)
library(httr)
library(jsonlite)
library(sf)
library(ggplot2)
library(ggspatial)
library(dplyr)
library(tidyr)
library(stringr)
# Downloading MN All Park ArcGIS data from Metropolitan Council
base_url2 <- "https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/rest/services/Parks/FeatureServer/0/query"
# geometryType=esriGeometryEnvelope&geometry={xmin: -104, ymin: 35.6, xmax: -94.32, ymax: 41}
# {
#   "x": <x>,
#   "y": <y>,
#   "z": <z>,
#   "m": <m>,
#   "id":<id>,
#   "spatialReference": { <spatialReference> }
# }
query_params2 <- list(
geometry = '{
"xmin": -10394540.56,
"ymin": 5603024.26,
"xmax": -10373503.03,
"ymax":  5629581.38,
"spatialReference": {"wkid":102100}
}',
geometryType2 = "esriGeometryEnvelope",
outFields = "*",
f = "geojson"
)
response2 <- GET(base_url2, query = query_params2)
geojson_data2 <- content(response2, as = "text", encoding = "UTF-8") %>% fromJSON()
temp_geojson2 <- tempfile(fileext = ".geojson")
writeBin(content(response2, as = "raw"), temp_geojson2)
# Read the GeoJSON data as a shape file object
geojson_sf_2 <- st_read(temp_geojson2)
# Downloading other important data from GitHub
svi <- read.csv("../data/clean/svi.csv")
holc <- st_read("../data/clean/redlining_msp_shp/redlining_msp.shp")
library(tigris)
library(tidycensus)
options(tigris_use_cache = TRUE)
mn_census_tract <- tracts(state = "MN", cb = FALSE, year = 2022) %>%
filter(COUNTYFP == "053") # collect hennepin county census tracts
minneapolis_boundary <- places(state = "MN", year = 2022, class = "sf") %>%
filter(NAME == "Minneapolis")
mn_lake <- area_water(state = "MN", count = 'Hennepin')
mpls_tracts <- st_intersection(mn_census_tract, minneapolis_boundary)
mpls_lakes <- st_intersection(mn_lake, minneapolis_boundary)
mpls_tracts <- st_transform(mpls_tracts, 4326) # make the same crs
mpls_lakes <- st_transform(mpls_lakes, 4326) # make the same crs
parks_in_tracts <- st_intersection(mpls_tracts, geojson_sf_2) # get overlapping area
parks_in_tracts_2 <- parks_in_tracts %>%
st_difference(st_union(mpls_lakes))
lakeless_tracts <- mpls_tracts %>%
st_difference(st_union(mpls_lakes))
# Goal: Create data frame with park area per tract
parks_in_tracts_3 <- parks_in_tracts_2 %>%
group_by(GEOID) %>% # Group by census tract
mutate(total_park_area = (sum(ACRES)*4046.86)) %>% # add total park acres per census tract and convert units
select(GEOID, total_park_area) %>% # select important cols
distinct(GEOID, .keep_all = TRUE) %>% # Get one number for each tract
st_drop_geometry() # Drop geometry for further data merge
# It is okay to drop geometry here because we are only going for the number area, not the shape of the park areas in the census tracts.
lakeless_tracts <- st_make_valid(lakeless_tracts)
# Goal: Add the total_park_area column to the mn_census_tract data so we can make a map with the total_park_area as the fill variable
mn_census_tract_2 <- lakeless_tracts %>%
left_join(parks_in_tracts_3, by = "GEOID") %>% # Match all ocurrences
mutate(total_park_area = replace_na(total_park_area, 0)) %>%
mutate(park_area_ratio = total_park_area / st_area(lakeless_tracts)) %>%
mutate(park_area_ratio = str_remove(park_area_ratio, "[1/m^2]")) %>%
mutate(park_area_ratio = as.numeric(park_area_ratio))
library(httr)
library(jsonlite)
library(sf)
library(ggplot2)
library(ggspatial)
library(dplyr)
library(tidyr)
library(stringr)
library(leaflet)
# Adding Leaflet Map
palette <- colorNumeric(palette = rev("Greens"), domain=mn_census_tract_2$total_park_area)
mn_census_tract_3 <- st_collection_extract(mn_census_tract_2, type = "POLYGON") %>%
mutate(total_park_area = round(total_park_area, digits = 2))
leaflet(data = mn_census_tract_3) %>%
addProviderTiles("OpenStreetMap") %>%
addPolygons(
fillColor = ~palette(total_park_area),
color = "black",
weight = 1,
opacity = 1,
fillOpacity = 0.9,
popup = ~paste("Park Area:", total_park_area)
) %>%
addLegend(
"bottomright",
pal = palette,
values = ~total_park_area,
title = "Total Park Area (m^2)",
opacity = 1
) %>%
addControl("Total Park Area by Census Tract in Minneapolis", position = "topright")
lm_redline_parks <- lm(total_park_area ~ holc_grade, data = redlining_parks)
# Redlining per census tract data from GitHub/Na's code
msp_census_tracts <- read.csv("../data/minneapolis-tree-canopy.csv") %>%  select(region_name)
# Redlining per census tract data from GitHub/Na's code
msp_census_tracts <- read.csv("../data/raw/minneapolis-tree-canopy.csv") %>%  select(region_name)
msp_census_tracts <- msp_census_tracts %>%
mutate(region_name = str_replace_all(region_name, '[:alpha:]*', "") %>% str_trim()) %>%
filter(region_name != "27123043002") %>%
filter(region_name != "27053980000") %>%
pull(region_name) %>%
as.list()
redlining <- st_read('../ds456_nrmc-main/data/raw/141121-V2/HRS2020B.shp')
# Redlining per census tract data from GitHub/Na's code
msp_census_tracts <- read.csv("../data/raw/minneapolis-tree-canopy.csv") %>%  select(region_name)
msp_census_tracts <- msp_census_tracts %>%
mutate(region_name = str_replace_all(region_name, '[:alpha:]*', "") %>% str_trim()) %>%
filter(region_name != "27123043002") %>%
filter(region_name != "27053980000") %>%
pull(region_name) %>%
as.list()
redlining <- st_read('../data/raw/141121-V2/HRS2020B.shp')
redlining_msp <- redlining %>%
filter(GEOID20 %in% msp_census_tracts) %>%
st_drop_geometry() %>%
rename(holc_grade = EQINTER20) %>%
mutate(holc_grade = case_when(
holc_grade == 1 ~ "A",
holc_grade == 2 ~ "B",
holc_grade == 3 ~ "C",
holc_grade == 4 ~ "D",
))
redlining_parks <- redlining_msp %>%
select(GEOID20, holc_grade) %>%
st_drop_geometry() %>%
inner_join(mn_census_tract_2, by = c("GEOID20" = "GEOID"))
lm_redline_parks <- lm(total_park_area ~ holc_grade, data = redlining_parks)
summary(lm_redline_parks)
# Redlining per census tract data from GitHub/Na's code
msp_census_tracts <- read.csv("../data/raw/minneapolis-tree-canopy.csv") %>%  select(region_name)
msp_census_tracts <- msp_census_tracts %>%
mutate(region_name = str_replace_all(region_name, '[:alpha:]*', "") %>% str_trim()) %>%
filter(region_name != "27123043002") %>%
filter(region_name != "27053980000") %>%
pull(region_name) %>%
as.list()
redlining <- st_read('../data/raw/141121-V2/HRS2020B.shp')
redlining_msp <- redlining %>%
filter(GEOID20 %in% msp_census_tracts) %>%
st_drop_geometry() %>%
rename(holc_grade = EQINTER20) %>%
mutate(holc_grade = case_when(
holc_grade == 1 ~ "A",
holc_grade == 2 ~ "B",
holc_grade == 3 ~ "C",
holc_grade == 4 ~ "D",
))
redlining_parks <- redlining_msp %>%
select(GEOID20, holc_grade) %>%
st_drop_geometry() %>%
inner_join(mn_census_tract_2, by = c("GEOID20" = "GEOID"))
lm_redline_parks <- lm(total_park_area ~ holc_grade, data = redlining_parks)
summary(lm_redline_parks)
# Redlining per census tract data from GitHub/Na's code
msp_census_tracts <- read.csv("../data/raw/minneapolis-tree-canopy.csv") %>%  select(region_name)
msp_census_tracts <- msp_census_tracts %>%
mutate(region_name = str_replace_all(region_name, '[:alpha:]*', "") %>% str_trim()) %>%
filter(region_name != "27123043002") %>%
filter(region_name != "27053980000") %>%
pull(region_name) %>%
as.list()
redlining <- st_read('../data/raw/141121-V2/HRS2020B.shp')
redlining_msp <- redlining %>%
filter(GEOID20 %in% msp_census_tracts) %>%
st_drop_geometry() %>%
rename(holc_grade = EQINTER20) %>%
mutate(holc_grade = case_when(
holc_grade == 1 ~ "A",
holc_grade == 2 ~ "B",
holc_grade == 3 ~ "C",
holc_grade == 4 ~ "D",
))
redlining_parks <- redlining_msp %>%
select(GEOID20, holc_grade) %>%
st_drop_geometry() %>%
inner_join(mn_census_tract_2, by = c("GEOID20" = "GEOID"))
lm_redline_parks <- lm(total_park_area ~ holc_grade, data = redlining_parks)
summary(lm_redline_parks)
# Redlining per census tract data from GitHub/Na's code
msp_census_tracts <- read.csv("../data/raw/minneapolis-tree-canopy.csv") %>%  select(region_name)
msp_census_tracts <- msp_census_tracts %>%
mutate(region_name = str_replace_all(region_name, '[:alpha:]*', "") %>% str_trim()) %>%
filter(region_name != "27123043002") %>%
filter(region_name != "27053980000") %>%
pull(region_name) %>%
as.list()
redlining <- st_read('../data/raw/141121-V2/HRS2020B.shp')
redlining_msp <- redlining %>%
filter(GEOID20 %in% msp_census_tracts) %>%
st_drop_geometry() %>%
rename(holc_grade = EQINTER20) %>%
mutate(holc_grade = case_when(
holc_grade == 1 ~ "A",
holc_grade == 2 ~ "B",
holc_grade == 3 ~ "C",
holc_grade == 4 ~ "D",
))
redlining_parks <- redlining_msp %>%
select(GEOID20, holc_grade) %>%
st_drop_geometry() %>%
inner_join(mn_census_tract_2, by = c("GEOID20" = "GEOID"))
lm_redline_parks <- lm(total_park_area ~ holc_grade, data = redlining_parks)
summary(lm_redline_parks)
